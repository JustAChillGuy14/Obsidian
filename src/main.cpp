#include <iostream>
#include <cstring>
#include <fstream>
#include <sstream>

#include "frontend/lexer.hpp"

bool match_prefix(std::string_view arg, std::string_view full)
{
    if (arg.size() > full.size())
        return false; // can't be longer
    return arg == full.substr(0, arg.size());
}

std::string read_entire_file_string(std::string filename, bool &failed)
{
    std::ifstream file(filename); // Opens in text mode by default

    if (!file.is_open())
    {
        failed = true;
        return "";
    }

    // Use a stringstream to efficiently read the entire file buffer
    std::stringstream buffer;
    buffer << file.rdbuf();

    failed = false;
    // Convert the stringstream buffer to a standard string
    return buffer.str();
}

typedef uint8_t FlagType;

#define TOKEN_FLAG 1

void usage(const char *name)
{
    std::cout << name << " [options] [file]..." << std::endl;
    std::cout << "options:" << std::endl;
    std::cout << "    -tokens dump tokens and stop immediately after tokenization." << std::endl;
    std::cout << "    -o <filename> outputs into filename" << std::endl;
    std::cout << "    --help print usage." << std::endl;
}

int main(int argc, char **argv)
{
    if (argc < 2)
    {
        usage(argv[0]);
        exit(EXIT_FAILURE);
    }
    
    FlagType flags = 0;
    bool flagend = false;

    std::string out = "a.out";
    std::string in  = "";
    for (int i = 1; i < argc; i++)
    {
        const char *arg = argv[i];
        if (!flagend && *arg == '-')
        {
            if (arg[1] == '-' && !arg[2])
            {
                flagend = true;
                continue;
            }
            
            if (match_prefix(arg, "-o"))
            {
                i++;
                if (i >= argc)
                {
                    std::cerr << "output file name not provided after `-o` flag" << std::endl;
                    exit(EXIT_FAILURE);
                }
                out = argv[i];
            }
            else if (match_prefix(arg, "-tokens"))
            {
                flags |= TOKEN_FLAG;
            }
            else if (match_prefix(arg, "--help"))
            {
                usage(argv[0]);
                exit(EXIT_SUCCESS);
            }
            else
            {
                std::cerr << "Unknown option `" << arg << "`" << std::endl;
                exit(EXIT_FAILURE);
            }
        }
        else
        {
            if (in != "")
            {
                // TODO: support multiple source files
                std::cerr << "Multiple source files are currently unsupported." << std::endl;
                exit(EXIT_FAILURE);
            }
            in = arg;
        }
    }

    bool failure;
    
    if (in == "")
    {
        std::cerr << "No source files provided" << std::endl;
        exit(EXIT_FAILURE);
    }
    
    std::string src = read_entire_file_string(in, failure);

    if (failure)
    {
        std::cerr << "Error while opening file " << in << std::endl;
        exit(EXIT_FAILURE);
    }
    

    lexer::Lexer l(src);
    std::vector<lexer::Token> tokens = l.tokenize(in,failure);
    
    if (failure)
    {
        std::vector<std::string> errors = l.get_errors();
        for (const std::string &error : errors)
        {
            std::cerr << error << "\n";
        }
        exit(EXIT_FAILURE);
    }
    
    if (flags & TOKEN_FLAG)
    {
        std::cout << "Tokens generated by the lexer from source file " << in << ":\n" << "[\n";
        for (const lexer::Token &token : tokens)
        {
            std::cout << "  {kind: " << lexer::tokentype_str(token.kind) << ", value: `" << token.value << "`}";
            if (token.kind != lexer::TokenType::_EOF)
            {
                std::cout << ",\n";
            }
        }
        std::cout << "\n]" << std::endl;
        exit(EXIT_SUCCESS);
    }
}